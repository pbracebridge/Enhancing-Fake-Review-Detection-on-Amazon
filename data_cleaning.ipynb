{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de91b7-bbb8-4c60-84bb-591df24d6d40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import numpy as np  # Numerical computations\n",
    "import re  # Regular expressions for text preprocessing\n",
    "from nltk.corpus import stopwords  # Stopwords list for filtering out common words\n",
    "from nltk.stem import WordNetLemmatizer  # Lemmatizer to reduce words to their base form\n",
    "import nltk  # Natural Language Toolkit for text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0f600-4aff-40c6-93ed-92e8255dc6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset from the specified file path\n",
    "file_path = 'data/fake_reviews_dataset.csv'\n",
    "reviews_dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Confirm successful loading and display the first few rows\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(reviews_dataset.head())  # Preview the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8572d821-4027-47af-9637-0a36d06168ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rename the 'text_' column to 'text'\n",
    "if 'text_' in reviews_dataset.columns:\n",
    "    reviews_dataset.rename(columns={'text_': 'text'}, inplace=True)\n",
    "    print(\"Renamed 'text_' column to 'text'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25986f0a-6aaf-4e08-9806-09f1791f199c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleans the specified text column: Removes NaN values, Converts values to strings, Removes empty/whitespace-only strings\n",
    "def clean_text_column(df, column_name):\n",
    "    initial_rows = df.shape[0]\n",
    "    \n",
    "    # Drop rows with NaN in the specified column\n",
    "    df = df.dropna(subset=[column_name])\n",
    "    rows_dropped_na = initial_rows - df.shape[0]\n",
    "    print(f\"Rows dropped due to NaN in '{column_name}': {rows_dropped_na}\")\n",
    "\n",
    "    # Convert all values in the column to strings and strip whitespace\n",
    "    df[column_name] = df[column_name].astype(str).str.strip()\n",
    "    \n",
    "    # Drop rows with empty or whitespace-only strings\n",
    "    df = df[df[column_name] != '']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the cleaning process to the 'text' column\n",
    "reviews_dataset = clean_text_column(reviews_dataset, 'text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8ac8a0-aaf8-4d31-8f71-7f4a4e008353",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Track initial row count\n",
    "initial_rows = reviews_dataset.shape[0]\n",
    "\n",
    "# Remove exact duplicate rows\n",
    "reviews_dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display number of duplicates removed\n",
    "print(f\"Rows dropped due to duplicates: {initial_rows - reviews_dataset.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faec1d0-d57b-4f60-826d-d3e50affffb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert labels to numeric (CG = 1, OR = 0)\n",
    "reviews_dataset['label'] = reviews_dataset['label'].map({'CG': 1, 'OR': 0})\n",
    "\n",
    "# Convert categories to numeric values using a mapping dictionary\n",
    "category_mapping = {\n",
    "    'Home_and_Kitchen_5': 0,\n",
    "    'Tools_and_Home_Improvement_5': 1,\n",
    "    'Movies_and_TV_5': 2,\n",
    "    'Electronics_5': 3,\n",
    "    'Sports_and_Outdoors_5': 4,\n",
    "    'Clothing_Shoes_and_Jewelry_5': 5,\n",
    "    'Toys_and_Games_5': 6,\n",
    "    'Books_5': 7,\n",
    "    'Kindle_Store_5': 8,\n",
    "    'Pet_Supplies_5': 9\n",
    "}\n",
    "reviews_dataset['category'] = reviews_dataset['category'].map(category_mapping)\n",
    "\n",
    "# Drop rows with NaN values after mapping\n",
    "reviews_dataset = reviews_dataset.dropna(subset=['label', 'category'])\n",
    "print(\"Labels and categories converted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56de13-ec0c-4617-8cda-05abbdb46496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Date Column to Datetime\n",
    "reviews_dataset['date'] = pd.to_datetime(reviews_dataset['date'], errors='coerce')\n",
    "print(\"Date column converted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451ef7f-2eda-4e8f-b917-ea438f61660e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing (Lemmatisation & Stopword Removal)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)   # Remove all non-alphabetic characters, keeping only letters and spaces\n",
    "    tokens = text.lower().split()   # Convert text to lowercase and split into words (tokens)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]   # Apply lemmatization and remove stopwords\n",
    "    return ' '.join(tokens)   # Reconstruct the cleaned text\n",
    "\n",
    "# Apply preprocessing to the 'text' column and store results in 'cleaned_text'\n",
    "reviews_dataset['cleaned_text'] = reviews_dataset['text'].apply(preprocess_text)\n",
    "print(\"Text preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8b006-901f-4437-81ca-725ef032315a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the cleaned dataset to a new CSV file\n",
    "reviews_dataset.to_csv('data/reviews_dataset_cleaned.csv', index=False)\n",
    "print(\"Cleaned dataset saved to 'reviews_dataset_cleaned.csv'\")\n",
    "\n",
    "# Display column names in the final dataset\n",
    "print(\"Columns in the cleaned dataset:\", reviews_dataset.columns.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
